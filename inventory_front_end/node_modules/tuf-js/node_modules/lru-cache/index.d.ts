// Project: https://github.com/isaacs/node-lru-cache
// Based initially on @types/lru-cache
// https://github.com/DefinitelyTyped/DefinitelyTyped
// used under the terms of the MIT License, shown below.
//
// DefinitelyTyped license:
// ------
// MIT License
//
// Copyright (c) Microsoft Corporation.
//
// Permission is hereby granted, free of charge, to any person obtaining a
// copy of this software and associated documentation files (the "Software"),
// to deal in the Software without restriction, including without limitation
// the rights to use, copy, modify, merge, publish, distribute, sublicense,
// and/or sell copies of the Software, and to permit persons to whom the
// Software is furnished to do so, subject to the following conditions:
//
// The above copyright notice and this permission notice shall be included
// in all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
// EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
// IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY
// CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
// TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
// SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE
// ------
//
// Changes by Isaac Z. Schlueter released under the terms found in the
// LICENSE file within this project.

/**
 * Integer greater than 0, representing some number of milliseconds, or the
 * time at which a TTL started counting from.
 */
declare type LRUMilliseconds = number

/**
 * An integer greater than 0, reflecting the calculated size of items
 */
declare type LRUSize = number

/**
 * An integer greater than 0, reflecting a number of items
 */
declare type LRUCount = number

declare class LRUCache<K, V> implements Iterable<[K, V]> {
  constructor(options: LRUCache.Options<K, V>)

  /**
   * Number of items in the cache.
   * Alias for {@link size}
   *
   * @deprecated since 7.0 use {@link size} instead
   */
  public readonly length: LRUCount

  public readonly max: LRUCount
  public readonly maxSize: LRUSize
  public readonly maxEntrySize: LRUSize
  public readonly sizeCalculation:
    | LRUCache.SizeCalculator<K, V>
    | undefined
  public readonly dispose: LRUCache.Disposer<K, V>
  /**
   * @since 7.4.0
   */
  public readonly disposeAfter: LRUCache.Disposer<K, V> | null
  public readonly noDisposeOnSet: boolean
  public readonly ttl: LRUMilliseconds
  public readonly ttlResolution: LRUMilliseconds
  public readonly ttlAutopurge: boolean
  public readonly allowStale: boolean
  public readonly updateAgeOnGet: boolean
  /**
   * @since 7.11.0
   */
  public readonly noDeleteOnStaleGet: boolean
  /**
   * @since 7.6.0
   */
  public readonly fetchMethod: LRUCache.Fetcher<K, V> | null

  /**
   * The total number of items held in the cache at the current moment.
   */
  public readonly size: LRUCount

  /**
   * The total size of items in cache when using size tracking.
   */
  public readonly calculatedSize: LRUSize

  /**
   * Add a value to the cache.
   */
  public set(
    key: K,
    value: V,
    options?: LRUCache.SetOptions<K, V>
  ): this

  /**
   * Return a value from the cache. Will update the recency of the cache entry
   * found.
   *
   * If the key is not found, {@link get} will return `undefined`. This can be
   * confusing when setting values specifically to `undefined`, as in
   * `cache.set(key, undefined)`. Use {@link has} to determine whether a key is
   * present in the cache at all.
   */
  public get(key: K, options?: LRUCache.GetOptions<V>): V | undefined

  /**
   * Like {@link get} but doesn't update recency or delete stale items.
   * Returns `undefined` if the item is stale, unless {@link allowStale} is set
   * either on the cache or in the options object.
   */
  public peek(key: K, options?: LRUCache.PeekOptions): V | undefined

  /**
   * Check if a key is in the cache, without updating the recency of use.
   * Will return false if the item is stale, even though it is technically
   * in the cache.
   *
   * Will not update item age unless {@link updateAgeOnHas} is set in the
   * options or constructor.
   */
  public has(key: K, options?: LRUCache.HasOptions<V>): boolean

  /**
   * Deletes a key out of the cache.
   * Returns true if the key was deleted, false otherwise.
   */
  public delete(key: K): boolean

  /**
   * Clear the cache entirely, throwing away all values.
   */
  public clear(): void

  /**
   * Delete any stale entries. Returns true if anything was removed, false
   * otherwise.
   */
  public purgeStale(): boolean

  /**
   * Find a value for which the supplied fn method returns a truthy value,
   * similar to Array.find().  fn is called as fn(value, key, cache).
   */
  public find(
    callbackFn: (
      value: V,
      key: K,
      cache: this
    ) => boolean | undefined | void,
    options?: LRUCache.GetOptions<V>
  ): V | undefined

  /**
   * Call the supplied function on each item in the cache, in order from
   * most recently used to least recently used.  fn is called as
   * fn(value, key, cache).  Does not update age or recenty of use.
   */
  public forEach<T = this>(
    callbackFn: (this: T, value: V, key: K, cache: this) => void,
    thisArg?: T
  ): void

  /**
   * The same as {@link forEach} but items are iterated over in reverse
   * order.  (ie, less recently used items are iterated over first.)
   */
  public rforEach<T = this>(
    callbackFn: (this: T, value: V, key: K, cache: this) => void,
    thisArg?: T
  ): void

  /**
   * Return a generator yielding the keys in the cache,
   * in order from most recently used to least recently used.
   */
  public keys(): Generator<K, void, void>

  /**
   * Inverse order version of {@link keys}
   *
   * Return a generator yielding the keys in the cache,
   * in order from least recently used to most recently used.
   */
  public rkeys(): Generator<K, void, void>

  /**
   * Return a generator yielding the values in the cache,
   * in order from most recently used to least recently used.
   */
  public values(): Generator<V, void, void>

  /**
   * Inverse order version of {@link values}
   *
   * Return a generator yielding the values in the cache,
   * in order from least recently used to most recently used.
   */
  public rvalues(): Generator<V, void, void>

  /**
   * Return a generator yielding `[key, value]` pairs,
   * in order from most recently used to least recently used.
   */
  public entries(): Generator<[K, V], void, void>

  /**
   * Inverse order version of {@link entries}
   *
   * Return a generator yielding `[key, value]` pairs,
   * in order from least recently used to most recently used.
   */
  public rentries(): Generator<[K, V], void, void>

  /**
   * Iterating over the cache itself yields the same results as
   * {@link entries}
   */
  public [Symbol.iterator](): Generator<[K, V], void, void>

  /**
   * Return an array of [key, entry] objects which can be passed to
   * cache.load()
   */
  public dump(): Array<[K, LRUCache.Entry<V>]>

  /**
   * Reset the cache and load in the items in entries in the order listed.
   * Note that the shape of the resulting cache may be different if the
   * same options are not used in both caches.
   */
  public load(
    cacheEntries: ReadonlyArray<[K, LRUCache.Entry<V>]>
  ): void

  /**
   * Evict the least recently used item, returning its value or `undefined`
   * if cache is empty.
   */
  public pop(): V | undefined

  /**
   * Deletes a key out of the cache.
   *
   * @deprecated since 7.0 use delete() instead
   */
  public del(key: K): boolean

  /**
   * Clear the cache entirely, throwing away all values.
   *
   * @deprecated since 7.0 use clear() instead
   */
  public reset(): void

  /**
   * Manually iterates over the entire cache proactively pruning old entries.
   *
   * @deprecated since 7.0 use purgeStale() instead
   */
  public prune(): boolean

  /**
   * Make an asynchronous cached fetch using the {@link fetchMethod} function.
   *
   * If multiple fetches for the same key are issued, then they will all be
   * coalesced into a single call to fetchMethod.
   *
   * Note that this means that handling options such as
   * {@link allowStaleOnFetchAbort}, {@link signal}, and
   * {@link allowStaleOnFetchRejection} will be determined by the FIRST fetch()
   * call for a given key.
   *
   * This is a known (fixable) shortcoming which will be addresed on when
   * someone complains about it, as the fix would involve added complexity and
   * may not be worth the costs for this edge case.
   *
   * since: 7.6.0
   */
  public fetch(
    key: K,
    options?: LRUCache.FetchOptions<K, V>
  ): Promise<V>

  /**
   * since: 7.6.0
   */
  public getRemainingTTL(key: K): LRUMilliseconds
}

declare namespace LRUCache {
  type DisposeReason = 'evict' | 'set' | 'delete'

  type SizeCalculator<K, V> = (value: V, key: K) => LRUSize
  type Disposer<K, V> = (
    value: V,
    key: K,
    reason: DisposeReason
  ) => void
  type Fetcher<K, V> = (
    key: K,
    staleValue: V | undefined,
    options: FetcherOptions<K, V>
  ) => Promise<V | void | undefined> | V | void | undefined

  interface DeprecatedOptions<K, V> {
    /**
     * alias for ttl
     *
     * @deprecated since 7.0 use options.ttl instead
     */
    maxAge?: LRUMilliseconds

    /**
     * alias for {@link sizeCalculation}
     *
     * @deprecated since 7.0 use {@link sizeCalculation} instead
     */
    length?: SizeCalculator<K, V>

    /**
     * alias for allowStale
     *
     * @deprecated since 7.0 use options.allowStale instead
     */
    stale?: boolean
  }

  interface LimitedByCount {
    /**
     * The number of most recently used items to keep.
     * Note that we may store fewer items than this if maxSize is hit.
     */
    max: LRUCount
  }

  type MaybeMaxEntrySizeLimit<K, V> =
    | {
        /**
         * The maximum allowed size for any single item in the cache.
         *
         * If a larger item is passed to {@link set} or returned by a
         * {@link fetchMethod}, then it will not be stored in the cache.
         */
        maxEntrySize: LRUSize
        sizeCalculation?: SizeCalculator<K, V>
      }
    | {}

  interface LimitedBySize<K, V> {
    /**
     * If you wish to track item size, you must provide a maxSize
     * n